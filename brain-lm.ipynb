{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pat/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/pat/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/pat/Library/Python/3.9/lib/python/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/pat/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from trl import SFTTrainer\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "os.environ['WANDB_DISABLED']=\"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Related installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import zipfile\n",
    "import torchaudio\n",
    "import matplotlib\n",
    "import timm\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pat/Library/Python/3.9/lib/python/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "/Users/pat/Library/Python/3.9/lib/python/site-packages/datasets/load.py:1461: FutureWarning: The repository for mozilla-foundation/common_voice_16_1 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_16_1\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading data: 100%|██████████| 1.15G/1.15G [00:53<00:00, 21.5MB/s]\n",
      "Downloading data: 100%|██████████| 1.06G/1.06G [00:48<00:00, 21.8MB/s]\n",
      "Downloading data: 100%|██████████| 945M/945M [00:43<00:00, 21.6MB/s] \n",
      "Downloading data: 100%|██████████| 835M/835M [00:38<00:00, 21.9MB/s] \n",
      "Downloading data: 100%|██████████| 1.05G/1.05G [00:48<00:00, 21.7MB/s]\n",
      "Downloading data: 100%|██████████| 142M/142M [00:06<00:00, 21.8MB/s] \n",
      "Downloading data: 100%|██████████| 287M/287M [00:13<00:00, 21.7MB/s] \n",
      "Downloading data: 100%|██████████| 8.91M/8.91M [00:02<00:00, 4.09MB/s]\n",
      "Downloading data: 100%|██████████| 3.04M/3.04M [00:01<00:00, 1.85MB/s]\n",
      "Downloading data: 100%|██████████| 2.97M/2.97M [00:01<00:00, 1.78MB/s]\n",
      "Downloading data: 100%|██████████| 56.6M/56.6M [00:02<00:00, 19.1MB/s]\n",
      "Downloading data: 100%|██████████| 2.64M/2.64M [00:01<00:00, 1.70MB/s]\n",
      "Reading metadata...: 32789it [00:00, 258101.93it/s]es/s]\n",
      "Generating train split: 32789 examples [00:03, 9520.38 examples/s] \n",
      "Reading metadata...: 11038it [00:00, 292632.03it/s]xamples/s]\n",
      "Generating validation split: 11038 examples [00:01, 9727.42 examples/s] \n",
      "Reading metadata...: 11038it [00:00, 294879.86it/s]s/s]\n",
      "Generating test split: 11038 examples [00:01, 9681.72 examples/s]\n",
      "Reading metadata...: 205532it [00:00, 279754.93it/s]s/s]\n",
      "Generating other split: 205532 examples [00:21, 9773.14 examples/s] \n",
      "Reading metadata...: 9250it [00:00, 289715.95it/s] examples/s]\n",
      "Generating invalidated split: 9250 examples [00:00, 9808.34 examples/s] \n"
     ]
    }
   ],
   "source": [
    "cv_16 = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"th\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 32789\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 11038\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 11038\n",
       "    })\n",
       "    other: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 205532\n",
       "    })\n",
       "    invalidated: Dataset({\n",
       "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "        num_rows: 9250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  =  cv_16['train'].remove_columns(['accent','variant','segment','gender','age','client_id','locale'])\n",
    "val = cv_16['validation'].remove_columns(['accent','variant','segment','gender','age','client_id','locale'])\n",
    "test = cv_16['test'].remove_columns(['accent','variant','segment','gender','age','client_id','locale'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = librosa.resample(y=audio,orig_sr=48000,target_sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = librosa.stft(audio,n_fft=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.40180641e-08+0.00000000e+00j,  1.43452088e-04+0.00000000e+00j,\n",
       "         2.98102860e-04+0.00000000e+00j, ...,\n",
       "        -2.71480013e-05+0.00000000e+00j, -1.17502618e-05+0.00000000e+00j,\n",
       "         8.91649526e-05+0.00000000e+00j],\n",
       "       [ 8.91292279e-09+1.88533876e-08j,  5.91775825e-06+1.84526781e-04j,\n",
       "        -1.22422404e-04-6.08518032e-05j, ...,\n",
       "         3.48718885e-04-8.63319309e-05j, -1.02888720e-04+1.10638676e-04j,\n",
       "        -7.39410977e-05-2.67159378e-05j],\n",
       "       [-2.14371439e-08+3.04601677e-08j, -2.52293741e-04+1.08765661e-04j,\n",
       "         5.26982345e-04+4.28556743e-04j, ...,\n",
       "        -5.40024598e-04-4.44289330e-04j,  1.08508855e-05+1.41702838e-04j,\n",
       "         1.02324181e-04+2.27756802e-05j],\n",
       "       ...,\n",
       "       [ 1.18098005e-11-1.13526442e-12j, -2.63099498e-08+8.63649019e-10j,\n",
       "        -1.37562793e-08-1.07847533e-08j, ...,\n",
       "         1.68813312e-08-8.44297726e-09j,  2.02497398e-09+1.39816827e-08j,\n",
       "         1.87490501e-08+2.22647932e-09j],\n",
       "       [ 1.14327213e-11-5.76775382e-13j, -2.76463246e-08+4.11589485e-10j,\n",
       "         1.86328856e-09-2.70986537e-09j, ...,\n",
       "         4.58032106e-09+5.68918780e-09j,  6.60217574e-09-1.06479497e-09j,\n",
       "         2.24514841e-08+1.41356885e-09j],\n",
       "       [ 1.14484543e-11+0.00000000e+00j, -2.77994303e-08+0.00000000e+00j,\n",
       "        -2.64661446e-09+0.00000000e+00j, ...,\n",
       "         7.35748240e-09+0.00000000e+00j, -9.51209044e-11+0.00000000e+00j,\n",
       "         2.20704422e-08+0.00000000e+00j]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:4719\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   4717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(normalize, (\u001b[38;5;28minput\u001b[39m, out), \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, eps\u001b[38;5;241m=\u001b[39meps, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m   4718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4719\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m(p, dim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mclamp_min(eps)\u001b[38;5;241m.\u001b[39mexpand_as(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   4720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m/\u001b[39m denom\n\u001b[1;32m   4721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'norm'"
     ]
    }
   ],
   "source": [
    "torch.nn.functional.normalize(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
